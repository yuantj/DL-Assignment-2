{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4402c02d",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47a7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 6)\n",
    "pd.set_option(\"display.max_rows\", 6)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894458f2",
   "metadata": {},
   "source": [
    "## Obtain the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22359754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      target  source\n",
      "0          0      21\n",
      "1          0     905\n",
      "2          0     906\n",
      "...      ...     ...\n",
      "5426    1874    2586\n",
      "5427    1876    1874\n",
      "5428    1897    2707\n",
      "\n",
      "[5429 rows x 2 columns]\n",
      "      paper_id  term_0  term_1  ...  term_1431  term_1432  subject\n",
      "0          462       0       0  ...          0          0        2\n",
      "1         1911       0       0  ...          0          0        5\n",
      "2         2002       0       0  ...          0          0        4\n",
      "...        ...     ...     ...  ...        ...        ...      ...\n",
      "2705      2372       0       0  ...          0          0        1\n",
      "2706       955       0       0  ...          0          0        0\n",
      "2707       376       0       0  ...          0          0        2\n",
      "\n",
      "[2708 rows x 1435 columns]\n"
     ]
    }
   ],
   "source": [
    "zip_file = keras.utils.get_file(\n",
    "    fname=\"cora.tgz\",\n",
    "    origin=\"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(zip_file), \"cora_extracted/cora\")\n",
    "\n",
    "citations = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.cites\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"target\", \"source\"],\n",
    ")\n",
    "\n",
    "papers = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.content\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"],\n",
    ")\n",
    "\n",
    "class_values = sorted(papers[\"subject\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}\n",
    "\n",
    "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
    "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])\n",
    "\n",
    "print(citations)\n",
    "\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c33e9",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461485d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain random indices\n",
    "random_indices = np.random.permutation(range(papers.shape[0]))\n",
    "\n",
    "# 50/50 split\n",
    "train_data = papers.iloc[random_indices[: len(random_indices) // 2]]\n",
    "test_data = papers.iloc[random_indices[len(random_indices) // 2 :]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8351fa6",
   "metadata": {},
   "source": [
    "### Prepare the graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037344f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges shape:\t\t (5429, 2)\n",
      "Node features shape: (2708, 1433)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:30:10.218833: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-04-15 19:30:10.218853: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 128.00 GB\n",
      "2025-04-15 19:30:10.218857: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 48.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744738210.218875 14039772 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1744738210.218896 14039772 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Obtain paper indices which will be used to gather node states\n",
    "# from the graph later on when training the model\n",
    "train_indices = train_data[\"paper_id\"].to_numpy()\n",
    "test_indices = test_data[\"paper_id\"].to_numpy()\n",
    "\n",
    "# Obtain ground truth labels corresponding to each paper_id\n",
    "train_labels = train_data[\"subject\"].to_numpy()\n",
    "test_labels = test_data[\"subject\"].to_numpy()\n",
    "\n",
    "# Define graph, namely an edge tensor and a node feature tensor\n",
    "edges = tf.convert_to_tensor(citations[[\"target\", \"source\"]])\n",
    "node_states = tf.convert_to_tensor(papers.sort_values(\"paper_id\").iloc[:, 1:-1])\n",
    "\n",
    "# Print shapes of the graph\n",
    "print(\"Edges shape:\\t\\t\", edges.shape)\n",
    "print(\"Node features shape:\", node_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b957df",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c89d06",
   "metadata": {},
   "source": [
    "### (Multi-head) graph attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267d3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        kernel_regularizer=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.kernel_attention = self.add_weight(\n",
    "            shape=(self.units * 2, 1),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel_attention\",\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "\n",
    "        # Linearly transform node states\n",
    "        node_states_transformed = tf.matmul(node_states, self.kernel)\n",
    "\n",
    "        # (1) Compute pair-wise attention scores\n",
    "        node_states_expanded = tf.gather(node_states_transformed, edges)\n",
    "        node_states_expanded = tf.reshape(\n",
    "            node_states_expanded, (tf.shape(edges)[0], -1)\n",
    "        )\n",
    "        attention_scores = tf.nn.leaky_relu(\n",
    "            tf.matmul(node_states_expanded, self.kernel_attention)\n",
    "        )\n",
    "        attention_scores = tf.squeeze(attention_scores, -1)\n",
    "\n",
    "        # (2) Normalize attention scores\n",
    "        attention_scores = tf.math.exp(tf.clip_by_value(attention_scores, -2, 2))\n",
    "        attention_scores_sum = tf.math.unsorted_segment_sum(\n",
    "            data=attention_scores,\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=tf.reduce_max(edges[:, 0]) + 1,\n",
    "        )\n",
    "        attention_scores_sum = tf.repeat(\n",
    "            attention_scores_sum, tf.math.bincount(tf.cast(edges[:, 0], \"int32\"))\n",
    "        )\n",
    "        attention_scores_norm = attention_scores / attention_scores_sum\n",
    "\n",
    "        # (3) Gather node states of neighbors, apply attention scores and aggregate\n",
    "        node_states_neighbors = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        out = tf.math.unsorted_segment_sum(\n",
    "            data=node_states_neighbors * attention_scores_norm[:, tf.newaxis],\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=tf.shape(node_states)[0],\n",
    "        )\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadGraphAttention(layers.Layer):\n",
    "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.merge_type = merge_type\n",
    "        self.attention_layers = [GraphAttention(units) for _ in range(num_heads)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        atom_features, pair_indices = inputs\n",
    "\n",
    "        # Obtain outputs from each attention head\n",
    "        outputs = [\n",
    "            attention_layer([atom_features, pair_indices])\n",
    "            for attention_layer in self.attention_layers\n",
    "        ]\n",
    "        # Concatenate or average the node states from each head\n",
    "        if self.merge_type == \"concat\":\n",
    "            outputs = tf.concat(outputs, axis=-1)\n",
    "        else:\n",
    "            outputs = tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)\n",
    "        # Activate and return node states\n",
    "        return tf.nn.relu(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09bac7",
   "metadata": {},
   "source": [
    "### Implement training logic with custom `train_step`, `test_step`, and `predict_step` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e35d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionNetwork(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_states,\n",
    "        edges,\n",
    "        hidden_units,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        output_dim,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_states = node_states\n",
    "        self.edges = edges\n",
    "        self.preprocess = layers.Dense(hidden_units * num_heads, activation=\"relu\")\n",
    "        self.attention_layers = [\n",
    "            MultiHeadGraphAttention(hidden_units, num_heads) for _ in range(num_layers)\n",
    "        ]\n",
    "        self.output_layer = layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "        x = self.preprocess(node_states)\n",
    "        for attention_layer in self.attention_layers:\n",
    "            x = attention_layer([x, edges]) + x\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        indices, labels = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            outputs = self([self.node_states, self.edges])\n",
    "            # Compute loss\n",
    "            loss = self.compiled_loss(labels, tf.gather(outputs, indices))\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        # Apply gradients (update weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(labels, tf.gather(outputs, indices))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        indices = data\n",
    "        # Forward pass\n",
    "        outputs = self([self.node_states, self.edges])\n",
    "        # Compute probabilities\n",
    "        return tf.nn.softmax(tf.gather(outputs, indices))\n",
    "\n",
    "    def test_step(self, data):\n",
    "        indices, labels = data\n",
    "        # Forward pass\n",
    "        outputs = self([self.node_states, self.edges])\n",
    "        # Compute loss\n",
    "        loss = self.compiled_loss(labels, tf.gather(outputs, indices))\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(labels, tf.gather(outputs, indices))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218bf5c",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e571811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:30:12.406478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-15 19:30:14.372244: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: RecvAsync is cancelled.\n",
      "\t [[{{node StatefulPartitionedCall/graph_attention_network_1/multi_head_graph_attention_1_2/graph_attention_15_1/Repeat/boolean_mask/Reshape_1/_200}}]] [type.googleapis.com/tensorflow.DerivedStatus='']\n",
      "2025-04-15 19:30:14.372260: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15658327722118963530\n",
      "2025-04-15 19:30:14.372265: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4976595774973092396\n",
      "2025-04-15 19:30:14.372269: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 2661653821152062926\n",
      "2025-04-15 19:30:14.372273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 9453521127897288494\n",
      "2025-04-15 19:30:14.372277: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10978800157364220792\n",
      "2025-04-15 19:30:14.372281: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 1247854059387409786\n",
      "2025-04-15 19:30:14.372284: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 7405927143777375868\n",
      "2025-04-15 19:30:14.372289: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 5704941548527809536\n",
      "2025-04-15 19:30:14.372293: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 8652602898045476088\n",
      "2025-04-15 19:30:14.372295: I tensorflow/core/framework/local_rendezvous.cc:430] Local rendezvous send item cancelled. Key hash: 15574517978273791342\n",
      "2025-04-15 19:30:14.372299: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 14901032813405584886\n",
      "2025-04-15 19:30:14.372303: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15344188335745179729\n",
      "2025-04-15 19:30:14.372307: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 5487961738187702513\n",
      "2025-04-15 19:30:14.372310: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 16907013941845271201\n",
      "2025-04-15 19:30:14.372313: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11617112763322483541\n",
      "2025-04-15 19:30:14.372316: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 376752454332793975\n",
      "2025-04-15 19:30:14.372319: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 17744317991863018959\n",
      "2025-04-15 19:30:14.372323: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 1127108113333348049\n",
      "2025-04-15 19:30:14.372327: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 16344541088235332935\n",
      "2025-04-15 19:30:14.372328: I tensorflow/core/framework/local_rendezvous.cc:430] Local rendezvous send item cancelled. Key hash: 3924227877816247067\n",
      "2025-04-15 19:30:14.372331: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 14244311903496195053\n",
      "2025-04-15 19:30:14.372334: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 8117474720918981633\n",
      "2025-04-15 19:30:14.372338: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12559003901170978115\n",
      "2025-04-15 19:30:14.372341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 18409912506825845855\n",
      "2025-04-15 19:30:14.372344: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 5445181519278420377\n",
      "2025-04-15 19:30:14.372346: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15942167027087725189\n",
      "2025-04-15 19:30:14.372350: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 2028765008077355427\n",
      "2025-04-15 19:30:14.372353: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 6379157885997423335\n",
      "2025-04-15 19:30:14.372357: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3694034663559002943\n",
      "2025-04-15 19:30:14.372360: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 2993132960225327375\n",
      "2025-04-15 19:30:14.372363: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 2419151176834726453\n",
      "2025-04-15 19:30:14.372366: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 7956480083997286093\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/graph_attention_network_1/multi_head_graph_attention_1/graph_attention_1/and defined at (most recent call last):\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/var/folders/kv/7fb5s97s7g33v041x087dh3m0000gn/T/ipykernel_44967/845968400.py\", line 28, in <module>\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/var/folders/kv/7fb5s97s7g33v041x087dh3m0000gn/T/ipykernel_44967/3672007774.py\", line 38, in train_step\n\nNo registered 'BroadcastTo' OpKernel for 'GPU' devices compatible with node {{node gradient_tape/graph_attention_network_1/multi_head_graph_attention_1/graph_attention_1/and}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_BOOL, Tidx=DT_INT32, _XlaHasReferenceVars=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"\n\t.  Registered:  device='XLA_CPU_JIT'; Tidx in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN, DT_FLOAT8_E4M3FNUZ, DT_FLOAT8_E4M3B11FNUZ, DT_FLOAT8_E5M2FNUZ, DT_INT4, DT_UINT4]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n  device='GPU'; T in [DT_BFLOAT16]\n  device='DEFAULT'; T in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]\n  device='CPU'; T in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_FLOAT8_E5M2]\n  device='CPU'; T in [DT_FLOAT8_E4M3FN]\n\n\t [[StatefulPartitionedCall/gradient_tape/graph_attention_network_1/multi_head_graph_attention_1/graph_attention_1/and]] [Op:__inference_multi_step_on_iterator_26664]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m gat_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss_fn, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[accuracy_fn])\n\u001b[0;32m---> 28\u001b[0m \u001b[43mgat_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m _, test_accuracy \u001b[38;5;241m=\u001b[39m gat_model\u001b[38;5;241m.\u001b[39mevaluate(x\u001b[38;5;241m=\u001b[39mtest_indices, y\u001b[38;5;241m=\u001b[39mtest_labels, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m38\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/graph_attention_network_1/multi_head_graph_attention_1/graph_attention_1/and defined at (most recent call last):\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/var/folders/kv/7fb5s97s7g33v041x087dh3m0000gn/T/ipykernel_44967/845968400.py\", line 28, in <module>\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/opt/anaconda3/envs/dl-course/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/var/folders/kv/7fb5s97s7g33v041x087dh3m0000gn/T/ipykernel_44967/3672007774.py\", line 38, in train_step\n\nNo registered 'BroadcastTo' OpKernel for 'GPU' devices compatible with node {{node gradient_tape/graph_attention_network_1/multi_head_graph_attention_1/graph_attention_1/and}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_BOOL, Tidx=DT_INT32, _XlaHasReferenceVars=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"\n\t.  Registered:  device='XLA_CPU_JIT'; Tidx in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN, DT_FLOAT8_E4M3FNUZ, DT_FLOAT8_E4M3B11FNUZ, DT_FLOAT8_E5M2FNUZ, DT_INT4, DT_UINT4]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n  device='GPU'; T in [DT_BFLOAT16]\n  device='DEFAULT'; T in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]\n  device='CPU'; T in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_FLOAT8_E5M2]\n  device='CPU'; T in [DT_FLOAT8_E4M3FN]\n\n\t [[StatefulPartitionedCall/gradient_tape/graph_attention_network_1/multi_head_graph_attention_1/graph_attention_1/and]] [Op:__inference_multi_step_on_iterator_26664]"
     ]
    }
   ],
   "source": [
    "# Define hyper-parameters\n",
    "HIDDEN_UNITS = 100\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 3\n",
    "OUTPUT_DIM = len(class_values)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "VALIDATION_SPLIT = 0.1\n",
    "LEARNING_RATE = 3e-1\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.SGD(LEARNING_RATE, momentum=MOMENTUM)\n",
    "accuracy_fn = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_acc\", min_delta=1e-5, patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Build model\n",
    "gat_model = GraphAttentionNetwork(\n",
    "    node_states, edges, HIDDEN_UNITS, NUM_HEADS, NUM_LAYERS, OUTPUT_DIM\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "gat_model.compile(loss=loss_fn, optimizer=optimizer, metrics=[accuracy_fn])\n",
    "\n",
    "gat_model.fit(\n",
    "    x=train_indices,\n",
    "    y=train_labels,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "_, test_accuracy = gat_model.evaluate(x=test_indices, y=test_labels, verbose=0)\n",
    "\n",
    "print(\"--\" * 38 + f\"\\nTest Accuracy {test_accuracy*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae3833",
   "metadata": {},
   "source": [
    "### Predict (probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = gat_model.predict(x=test_indices)\n",
    "\n",
    "mapping = {v: k for (k, v) in class_idx.items()}\n",
    "\n",
    "for i, (probs, label) in enumerate(zip(test_probs[:10], test_labels[:10])):\n",
    "    print(f\"Example {i+1}: {mapping[label]}\")\n",
    "    for j, c in zip(probs, class_idx.keys()):\n",
    "        print(f\"\\tProbability of {c: <24} = {j*100:7.3f}%\")\n",
    "    print(\"---\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9520b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://keras.io/examples/graph/gat_node_classification/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
